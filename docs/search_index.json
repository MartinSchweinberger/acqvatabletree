[["index.html", "AcqVA Aurora Workshop: From Tables to Trees Part 1 General Information 1.1 Timeline", " AcqVA Aurora Workshop: From Tables to Trees Martin Schweinberger 2022-06-16 Part 1 General Information The materials for this workshop are available at https://martinschweinberger.github.io/acqvatabletree/ 1.1 Timeline Part 1: Working with tables in R (10-11:30) Break (11:30 - 12:30) Part 2: Tree-based models (12:30-14:00) This workshop consists of two parts and it is aimed at beginners and intermediate users of R. Part 1 showcases how to work with and process tabulated data (tables) using R. "],["working-with-tables.html", "Part 2 Working with Tables 2.1 Preparation and session set up 2.2 Getting started 2.3 Loading tables into R 2.4 Inspecting tables 2.5 Processing tabular data 2.6 Piping 2.7 Selecting and filtering 2.8 Changing data and adding columns 2.9 Renaming columns 2.10 Grouping and summarising 2.11 Gathering and Spreading 2.12 Saving tables on your computer 2.13 References", " Part 2 Working with Tables 2.1 Preparation and session set up This tutorial is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R here. For this tutorials, we need to install certain packages from an R library so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the packages so you do not need to worry if it takes some time). # install packages #install.packages(&quot;xlsx&quot;) install.packages(&quot;dplyr&quot;) install.packages(&quot;tidyr&quot;) #install.packages(&quot;openxlsx&quot;) install.packages(&quot;here&quot;) Now that we have installed the packages, we can activate them as shown below. # load packages library(dplyr) library(tidyr) #library(xlsx) #library(openxlsx) library(here) Once you have installed RStudio and initiated the session by executing the code shown above, you are good to go. 2.2 Getting started Tables are one of the most common and important ways to process, handle, and describe data. This tutorial introduces different types of tables, how to load and save different types of tables, as well as how to modify and process tables and tabulated data. When working with R, there are different kinds or types of tables that have different characteristics. The most common types of tables in R are: matrices data frames tibbles Matrices can only contain one type of data and all data points will be converted to the type of scale with the lowest information value. For instance, if at least one variables in a table represents characters (or strings), then all other variables are also converted into characters (although they may be numbers). Data frames can contain different types of scales and variables are not converted automatically. In this sense, data frames are more flexible and are preferable over matrices. Tibbles are the tidyverse equivalent of data frames which offer new functions and possibilities of handling and inspecting the data. . 2.3 Loading tables into R Loading rda-files There are several different functions that allow us to read tabulated data into R. In our case, we use the readRDS function which loads Rdata sets. # load data with read.delim mytable &lt;- base::readRDS(here::here(&quot;data&quot;, &quot;myrda.rda&quot;)) # inspect head(mytable) ## ID_rater ID_child age_group accent_response accent_numeric rating_language age_months family ## 1 R1 002SIN preschool s 2 DE 64 bil-rus ## 2 R2 002SIN preschool s 2 DE 64 bil-rus ## 3 R3 002SIN preschool s 2 DE 64 bil-rus ## 4 R4 002SIN preschool s 2 DE 64 bil-rus ## 5 R5 002SIN preschool s 2 DE 64 bil-rus ## 6 R6 002SIN preschool s 2 DE 64 bil-rus Loading txt-files If the data is stored as a txt-file, there are various functions to read in the data. The most common functions are read.delim and read.table. # load data with read.delim tab1 &lt;- read.delim(here::here(&quot;data&quot;, &quot;mlrdata.txt&quot;), sep = &quot;\\t&quot;, header = TRUE) # load data from a server/website #tab2 &lt;- read.table(&quot;https://slcladal.github.io/data/mlrdata.txt&quot;, header = TRUE) # inspect head(tab1) ## status attraction money ## 1 Relationship NotInterested 86.33 ## 2 Relationship NotInterested 45.58 ## 3 Relationship NotInterested 68.43 ## 4 Relationship NotInterested 52.93 ## 5 Relationship NotInterested 61.86 ## 6 Relationship NotInterested 48.47 Loading xlsx-files To load excel data you can use the read_excel function from the readxl package (which is part of the tidyverse). # load data excelcomp &lt;- readxl::read_excel(here::here(&quot;data&quot;, &quot;data_german.xlsx&quot;), sheet = 1) # inspect head(excelcomp) ## # A tibble: 6 × 8 ## ID_rater ID_child age_group accent_response accent_numeric rating_language age_months family ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 R1 002SIN preschool s 2 DE 64 bil-rus ## 2 R2 002SIN preschool s 2 DE 64 bil-rus ## 3 R3 002SIN preschool s 2 DE 64 bil-rus ## 4 R4 002SIN preschool s 2 DE 64 bil-rus ## 5 R5 002SIN preschool s 2 DE 64 bil-rus ## 6 R6 002SIN preschool s 2 DE 64 bil-rus Loading csv-files # load data csvdat &lt;- read.csv(here::here(&quot;data&quot;, &quot;mycsv.csv&quot;)) # inspect head(csvdat) ## X ID_rater ID_child age_group accent_response accent_numeric rating_language age_months family ## 1 1 R1 002SIN preschool s 2 DE 64 bil-rus ## 2 2 R2 002SIN preschool s 2 DE 64 bil-rus ## 3 3 R3 002SIN preschool s 2 DE 64 bil-rus ## 4 4 R4 002SIN preschool s 2 DE 64 bil-rus ## 5 5 R5 002SIN preschool s 2 DE 64 bil-rus ## 6 6 R6 002SIN preschool s 2 DE 64 bil-rus 2.4 Inspecting tables The most common functions that are used to inspect tabular data are the head() and the str() functions. The head() function shows the first 6 lines (by default) but we can also specify the number of rows. The str() function provides a summary of the structure of the data. Inspecting the first 6 rows of a table. head(mytable) ## ID_rater ID_child age_group accent_response accent_numeric rating_language age_months family ## 1 R1 002SIN preschool s 2 DE 64 bil-rus ## 2 R2 002SIN preschool s 2 DE 64 bil-rus ## 3 R3 002SIN preschool s 2 DE 64 bil-rus ## 4 R4 002SIN preschool s 2 DE 64 bil-rus ## 5 R5 002SIN preschool s 2 DE 64 bil-rus ## 6 R6 002SIN preschool s 2 DE 64 bil-rus Inspecting the first 10 rows of a table. head(mytable, 10) ## ID_rater ID_child age_group accent_response accent_numeric rating_language age_months family ## 1 R1 002SIN preschool s 2 DE 64 bil-rus ## 2 R2 002SIN preschool s 2 DE 64 bil-rus ## 3 R3 002SIN preschool s 2 DE 64 bil-rus ## 4 R4 002SIN preschool s 2 DE 64 bil-rus ## 5 R5 002SIN preschool s 2 DE 64 bil-rus ## 6 R6 002SIN preschool s 2 DE 64 bil-rus ## 7 R7 002SIN preschool s 2 DE 64 bil-rus ## 8 R8 002SIN preschool s 2 DE 64 bil-rus ## 9 R9 002SIN preschool s 2 DE 64 bil-rus ## 10 R10 002SIN preschool w 1 DE 64 bil-rus Checking the structure of tabulated data. str(mytable) ## &#39;data.frame&#39;: 777 obs. of 8 variables: ## $ ID_rater : chr &quot;R1&quot; &quot;R2&quot; &quot;R3&quot; &quot;R4&quot; ... ## $ ID_child : chr &quot;002SIN&quot; &quot;002SIN&quot; &quot;002SIN&quot; &quot;002SIN&quot; ... ## $ age_group : chr &quot;preschool&quot; &quot;preschool&quot; &quot;preschool&quot; &quot;preschool&quot; ... ## $ accent_response: chr &quot;s&quot; &quot;s&quot; &quot;s&quot; &quot;s&quot; ... ## $ accent_numeric : int 2 2 2 2 2 2 2 2 2 1 ... ## $ rating_language: chr &quot;DE&quot; &quot;DE&quot; &quot;DE&quot; &quot;DE&quot; ... ## $ age_months : int 64 64 64 64 64 64 64 64 64 64 ... ## $ family : chr &quot;bil-rus&quot; &quot;bil-rus&quot; &quot;bil-rus&quot; &quot;bil-rus&quot; ... The following section shows how to access and manipulate tables. 2.5 Processing tabular data The tidyverse is a specific way of writing R code that builds on a family of libraries designed for efficient data science work flows which were developed initially by Hadley Wickham. This new way of writing R code builds on a shared and underlying design philosophy and grammar. Due to its popularity and ease of use, the tidyverse way to write R code is becoming increasingly popular and we will use it in the following to handle and manipulate tabulated data. If you have already loaded data into R and now want to process the data, you typically have to modify the data in some form or another to get the information or format you need. The tidyverse offers very user-friendly, intuitive, and handy functions for processing the data to match the needs of your analysis. To have access to the tidyverse functions for data processing, we load the tidyverse package and load and inspect another set of data using the read.delim function. The new data is stored as a txt file and has 100 observations (rows) and 3 variables (status, attraction, and money). The data set represents how much money people have spend in someone they were interested in or not (attraction: Interested versus NotInterested) and their own relationship status (status: Single versus Relationship). # load new data newdata &lt;- read.delim(here::here(&quot;data&quot;, &quot;mlrdata.txt&quot;), sep = &quot;\\t&quot;, header = TRUE) # inspect head(newdata) ## status attraction money ## 1 Relationship NotInterested 86.33 ## 2 Relationship NotInterested 45.58 ## 3 Relationship NotInterested 68.43 ## 4 Relationship NotInterested 52.93 ## 5 Relationship NotInterested 61.86 ## 6 Relationship NotInterested 48.47 The table represents 3 variables (status, attraction, and money) and each row contains information on the relationship status of 100 people and how much money these people would spend on a gift to someone of the opposite sex who they are or are not interested in. We will now check out different ways and functions to process this data. 2.6 Piping Piping, done with the sequence %&gt;%, is a very easy, intuitive, quick, and handy way to process data. Essentially piping means that we take an element that is to the left of the piping symbol and then do something to it; that way, the piping symbol can be translated as and then. We could, for example, load data and then capitalize the column names and then group the data by status and attraction and then get the mean of money spend on deleting all observations except for the first one. A more formal way to write this would be: load %&gt;% capitalize %&gt;% group %&gt;% summarize. In R this command would look like this: # example of a data processing pipeline pipeddata &lt;- read.delim(here::here(&quot;data&quot;, &quot;mlrdata.txt&quot;), sep = &quot;\\t&quot;, header = TRUE) %&gt;% dplyr::rename(Status = status, Attraction = attraction, Money = money) %&gt;% dplyr::group_by(Status, Attraction) %&gt;% dplyr::summarise(Mean = mean(Money)) # inspect summarized data pipeddata ## # A tibble: 4 × 3 ## # Groups: Status [2] ## Status Attraction Mean ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Relationship Interested 99.2 ## 2 Relationship NotInterested 51.5 ## 3 Single Interested 157. ## 4 Single NotInterested 46.0 The pipe has worked and we get the resulting summary which shows the mean of the money spend based on Attraction and Status. 2.7 Selecting and filtering Among the most frequent procedures in data processing is selecting certain columns or extracting rows based on variable levels. In the tidyverse, this is done by using the select and filter functions. While select allows to extract columns, filter is used to extract rows, e.g. to get only observations that have a certain feature. Have a look at the example below. # select and filter reduceddata &lt;- newdata %&gt;% # select the columns attraction and money dplyr::select(attraction, money) %&gt;% # extract rows which represent cases where the person was interested in someone dplyr::filter(attraction == &quot;Interested&quot;) # inspect new table nrow(reduceddata); table(reduceddata$attraction) ## [1] 50 ## ## Interested ## 50 We have now reduced the data by excluding status (we have only selected attraction and money) and we have removed those 50 data rows of people who were not interested. The select function (like most other tidyverse functions) can also be used together with a minus sign which causes a column to be removed, thus dplyr::select(-money) would remove the money column (see below). # select and filter datawithoutmoney &lt;- newdata %&gt;% # remove money dplyr::select(-money) # inspect data head(datawithoutmoney) ## status attraction ## 1 Relationship NotInterested ## 2 Relationship NotInterested ## 3 Relationship NotInterested ## 4 Relationship NotInterested ## 5 Relationship NotInterested ## 6 Relationship NotInterested Selecting and filtering are extremely powerful functions that can also be combined with other functions. But before we discuss more complex issues, we will have a look at how we can change columns. 2.8 Changing data and adding columns Changing and adding data is done with the mutate function. The mutate functions requires that we specify a column name - if we use the same name as the column we are changing, then we change the column but if we specify another column name, then a new column is created. We will now create a new column (Spendalot) in which we encode if the person has spend a lot of money (100 AUD or more) on the present or not (less than 100 AUD). # creating a new column newdata &lt;- newdata %&gt;% dplyr::mutate(Spendalot = ifelse(money &gt;= 100, &quot;Alot&quot;, &quot;Alittle&quot;)) # inspect data head(newdata) ## status attraction money Spendalot ## 1 Relationship NotInterested 86.33 Alittle ## 2 Relationship NotInterested 45.58 Alittle ## 3 Relationship NotInterested 68.43 Alittle ## 4 Relationship NotInterested 52.93 Alittle ## 5 Relationship NotInterested 61.86 Alittle ## 6 Relationship NotInterested 48.47 Alittle The table now has a new column (Spendalot) because we have specified a column name that did not exist yet - had we written dplyr::mutate(money = ifelse(money &gt;= 100, \"Alot\", \"Alittle\")) then we would have changed the money column and replaced the money values with the labels Alot and Alittle. 2.9 Renaming columns Oftentimes, column names are not really meaningful or incoherent which makes it easier to wrap your head around what the values in a column refer to. The easiest way around this is rename columns which is, fortunately very simple in the tidyverse. While the column names of our example table are meaningful, I want to capitalize the first letter of each column name. This can be done as follows. # renaming columns newdata &lt;- newdata %&gt;% dplyr::rename(Status = status, Attraction = attraction, Money = colnames(.)[3]) # inspect data head(newdata) ## Status Attraction Money Spendalot ## 1 Relationship NotInterested 86.33 Alittle ## 2 Relationship NotInterested 45.58 Alittle ## 3 Relationship NotInterested 68.43 Alittle ## 4 Relationship NotInterested 52.93 Alittle ## 5 Relationship NotInterested 61.86 Alittle ## 6 Relationship NotInterested 48.47 Alittle The renaming was successful as all column names now begin with a capital letter. 2.10 Grouping and summarising In contrast to mutate, which retains the number of rows, summarizing creates new columns but collapses rows and only provides the summary value (or values if more than one summary is specified). Also, columns that are not grouping variables are removed. Summarizing is particularly useful when we want to get summaries of groups. We will modify the example from above and extract the mean and the standard deviation of the money spend on presents by relationship status and whether the giver was attracted to the giv-ee. #grouping and summarizing data datasummary &lt;- newdata %&gt;% dplyr::group_by(Status, Attraction) %&gt;% dplyr::summarise(Mean = round(mean(Money), 2), SD = round(sd(Money), 1)) # inspect summarized data datasummary ## # A tibble: 4 × 4 ## # Groups: Status [2] ## Status Attraction Mean SD ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Relationship Interested 99.2 14.7 ## 2 Relationship NotInterested 51.5 17 ## 3 Single Interested 157. 23.2 ## 4 Single NotInterested 46.0 19.9 2.11 Gathering and Spreading One very common problem is that data - or at least parts of it - have to be transformed from long to wide format or vice versa. In the tidyverse, this is done using the gather and spread function. We will convert the summary table shown above into a wide format (we also remove the SD column as it is no longer needed) # converting data to wide format widedata &lt;- datasummary %&gt;% # remove SD column dplyr::select(-SD) %&gt;% # convert into wide format tidyr::spread(Attraction, Mean) # inspect wide data widedata ## # A tibble: 2 × 3 ## # Groups: Status [2] ## Status Interested NotInterested ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Relationship 99.2 51.5 ## 2 Single 157. 46.0 We can re-convert the wide into a long format using the gather function. # converting data to long format longdata &lt;- widedata %&gt;% # convert into long format tidyr::gather(Attraction, Money, Interested:NotInterested) # inspect wide data longdata ## # A tibble: 4 × 3 ## # Groups: Status [2] ## Status Attraction Money ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Relationship Interested 99.2 ## 2 Single Interested 157. ## 3 Relationship NotInterested 51.5 ## 4 Single NotInterested 46.0 There are many more useful functions for processing, handling, and summarizing tables but this should suffice to get you started. 2.12 Saving tables on your computer There are different ways to save your data depending on the format in which you want to save your data. sessionInfo() ## R version 4.2.0 (2022-04-22 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19043) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_Australia.utf8 LC_CTYPE=English_Australia.utf8 LC_MONETARY=English_Australia.utf8 ## [4] LC_NUMERIC=C LC_TIME=English_Australia.utf8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] here_1.0.1 tidyr_1.2.0 dplyr_1.0.9 ## ## loaded via a namespace (and not attached): ## [1] Rcpp_1.0.8.3 mvtnorm_1.1-3 lattice_0.20-45 zoo_1.8-10 assertthat_0.2.1 rprojroot_2.0.3 ## [7] digest_0.6.29 utf8_1.2.2 R6_2.5.1 cellranger_1.1.0 stats4_4.2.0 evaluate_0.15 ## [13] highr_0.9 pillar_1.7.0 gdtools_0.2.4 rlang_1.0.2 multcomp_1.4-19 uuid_1.1-0 ## [19] readxl_1.4.0 rstudioapi_0.13 data.table_1.14.2 jquerylib_0.1.4 rpart_4.1.16 Matrix_1.4-1 ## [25] partykit_1.2-15 flextable_0.7.1 rmarkdown_2.14 splines_4.2.0 stringr_1.4.0 compiler_4.2.0 ## [31] xfun_0.31 pkgconfig_2.0.3 systemfonts_1.0.4 base64enc_0.1-3 libcoin_1.0-9 htmltools_0.5.2 ## [37] tidyselect_1.1.2 gridExtra_2.3 tibble_3.1.7 bookdown_0.27 coin_1.4-2 codetools_0.2-18 ## [43] matrixStats_0.62.0 randomForest_4.7-1.1 fansi_1.0.3 crayon_1.5.1 MASS_7.3-57 grid_4.2.0 ## [49] vip_0.3.2 jsonlite_1.8.0 gtable_0.3.0 lifecycle_1.0.1 DBI_1.1.2 magrittr_2.0.3 ## [55] zip_2.2.0 stringi_1.7.6 cli_3.3.0 tree_1.0-41 party_1.3-10 strucchange_1.5-2 ## [61] bslib_0.3.1 xml2_1.3.3 ellipsis_0.3.2 generics_0.1.2 vctrs_0.4.1 sandwich_3.0-1 ## [67] Formula_1.2-4 TH.data_1.1-1 tools_4.2.0 glue_1.6.2 officer_0.4.2 purrr_0.3.4 ## [73] parallel_4.2.0 fastmap_1.1.0 survival_3.3-1 yaml_2.3.5 inum_1.0-4 knitr_1.39 ## [79] sass_0.4.1 modeltools_0.2-23 2.13 References "],["tree-based-models.html", "Part 3 Tree-Based Models 3.1 Tree-Structure Model Basics 3.2 Classification And Regression Trees 3.3 Splitting numeric, ordinal, and true categorical variables 3.4 Conditional Inference Trees 3.5 Random Forests 3.6 Random Forests in R 3.7 Boruta", " Part 3 Tree-Based Models This tutorial focuses on tree-based models and their implementation in R. For the more advanced, a recommendable resource for tree-based modeling is @prasad2006newer or @gries2021statistics. Very good papers dealing with many critical issues related to tree-based models are @strobl2009tree and @breiman2001modeling. This tutorial is aimed at intermediate and advanced users of R with the aim of showcasing how to perform tree-based modeling and classification using R. The aim is not to provide a fully-fledged analysis but rather to show and exemplify how to implement and perform basic tree-based modeling and classification using R. The entire R Notebook for the tutorial can be downloaded here. If you want to render the R Notebook on your machine, i.e. knitting the document to html or a pdf, you need to make sure that you have R and RStudio installed and you also need to download the bibliography file and store it in the same folder where you store the Rmd file. Preparation and session set up This tutorial is based on R. If you have not installed R or are new to it, you will find an introduction to and more information how to use R here. For this tutorials, we need to install certain packages from an R library so that the scripts shown below are executed without errors. Before turning to the code below, please install the packages by running the code below this paragraph. If you have already installed the packages mentioned below, then you can skip ahead and ignore this section. To install the necessary packages, simply run the following code - it may take some time (between 1 and 5 minutes to install all of the libraries so you do not need to worry if it takes some time). # install packages install.packages(&quot;Boruta&quot;) install.packages(&quot;tree&quot;) install.packages(&quot;caret&quot;) install.packages(&quot;cowplot&quot;) install.packages(&quot;tidyverse&quot;) install.packages(&quot;ggparty&quot;) install.packages(&quot;Gmisc&quot;) install.packages(&quot;grid&quot;) install.packages(&quot;Hmisc&quot;) install.packages(&quot;party&quot;) install.packages(&quot;partykit&quot;) install.packages(&quot;randomForest&quot;) #install.packages(&quot;Rling&quot;) install.packages(&quot;pdp&quot;) install.packages(&quot;tidyr&quot;) install.packages(&quot;RCurl&quot;) install.packages(&quot;vip&quot;) install.packages(&quot;flextable&quot;) Now that we have installed the packages, we can activate them as shown below. # load packages library(Boruta) library(tree) library(caret) library(cowplot) library(tidyverse) library(ggparty) library(Gmisc) library(grid) library(Hmisc) library(party) library(partykit) library(randomForest) #library(Rling) library(pdp) library(RCurl) library(tidyr) library(vip) library(flextable) NOTEIn some cases, installing the caret package can be a bit more complicated. In my case, it was necessary to execute the code chunk shown below. However, once the caret package is installed, you do not need to go through these steps again and can simply activate it by calling library(caret). ` # install caret library source(&quot;https://bioconductor.org/biocLite.R&quot;); biocLite(); library(Biobase) install.packages(&quot;Biobase&quot;, repos=c(&quot;http://rstudio.org/_packages&quot;, &quot;http://cran.rstudio.com&quot;, &quot;http://cran.rstudio.com/&quot;, dependencies=TRUE)) install.packages(&quot;dimRed&quot;, dependencies = TRUE) install.packages(&#39;caret&#39;, dependencies = TRUE) # activate caret library library(caret) ` Once you have installed R, RStudio, and have also initiated the session by executing the code shown above, you are good to go. 3.1 Tree-Structure Model Basics This section deals with tree-structure models which fall into the machine-learning rather than the inference statistics category as they are commonly used for classification and prediction tasks rather than explanation of relationships between variables. The most basic type of tree-structure model is a decision tree or CART (classification and regression tree). A more optimized version of CARTs are conditional inference trees (CITs) - although CART and CITs are commonly treated as one and the same thing although CITs differ from CARTs in that they provide more accurate variable importance measures. Like random forests, inference trees are non-parametric and thus do not rely on distributional requirements (or at least on fewer). The tree structure represents recursive partitioning of the data to minimize residual deviance. Several advantages have been associated with using tree-based models: Tree-structure models are very useful because they can deal with different types of variables and provide a very good understanding of the structure in the data. Tree-structure models have been deemed particularly interesting for linguists because they can handle moderate sample sizes and many high-order interactions better then regression models shows that there can be issues especially when dealing with small data samples, single trees (rather than forests), and data where the variance is predictable based on a single interaction (as shown by @gries2021statistics, chapter 7). Tree-structure models are (supposedly) better at detecting non-linear or non-monotonic relationships between predictors and dependent variables. Tree-structure models are easy to implement in R and do not require the model selection, validation, and diagnostics associated with regression models. Tree-structure models can be used as variable-selection procedure which informs about which variables have any sort of significant relationship with the dependent variable and can thereby inform model fitting. Despite these potential advantages, a word of warning is in order: @gries2021statistics admits that tree-based models can be very useful but there are some issues that but some serious short-comings of tree-structure models remain under-explored. For instance, Tree-structure models only inform about the importance of a variable but not if the variable is important as a main effect or as part of interactions (or both)! The importance only shows that there is some important connection between the predictor and the dependent variable. Simple tree-structure models have been shown to fail in detecting the correct predictors if the variance is solely determined by a single interaction [@gries2021statistics, chapter 7.3]. This failure is caused by the fact that the predictor used in the first split of a tree is selected as the one with the strongest main effect [@boulesteix2015interaction, 344]. This issue can, however, be avoided by hard-coding the interactions as predictors plus using ensemble methods such as random forests rather than individual trees [see @gries2021statistics, chapter 7.3]. Another shortcoming is that tree-structure models partition the data (rather than “fitting a line” through the data which can lead to more coarse-grained predictions compared to regression models when dealing with numeric dependent variables [again, see @gries2021statistics, chapter 7.3]. @boulesteix2015interaction, 341 state that high correlations between predictors can hinder the detection of interactions when using small data sets. However, regression do not fare better here as they are even more strongly affected by (multi-)collinearity (see @@gries2021statistics, chapter 7.3). Tree-structure models are bad a detecting interactions when the variables have strong main effects which is, unfortunately, common when dealing with linguistic data [@wrigt2016interac]. Before we implement a conditional inference tree in R, we will have a look at how decision trees work. We will do this in more detail here as random forests and Boruta analyses are extensions of inference trees and are therefore based on the same concepts. 3.2 Classification And Regression Trees The most basic type of tree-structure model is a decision tree which is a type of classification and regression tree (CART). A more elaborate version of a CART is called a Conditional Inference Tree (CIT). The difference between a CART and a CIT is that CITs use significance tests, e.g. the p-values, to select and split variables rather than some information measures like the Gini coefficient [@gries2021statistics]. Below is an example of a decision tree which shows what what response to expect - in this case whether a speaker uses discourse like or not. Decision trees, like all CARTs and CITs, answer a simple question, namely How do we best classify elements based on the given predictors?. The answer that decision trees provide is the classification of the elements based on the levels of the predictors. In simple decision trees, all predictors, even those that are not significant are included in the decision tree. The decision tree shows that the best (or most important) predictor for the use of discourse like is age as it is the highest node. Among young speakers, those with high status use like more compared with speakers of lower social status. Among old speakers, women use discourse like more than men. The yes and no at the bottom show if the speaker should be classified as a user of discourse like (yes or no). Each split can be read as true to the left and false to the right. So that, at the first split, if the person is between the ages of 15 and 40, we need to follow the branch to the left while we need to follow to the right if the person is not 15 to 40. Before going through how this conditional decision tree is generated, let us first go over some basic concepts. The top of the decision tree is called root or root node, the categories at the end of branches are called leaves or leaf nodes. Nodes that are in-between the root and leaves are called internal nodes or just nodes. The root node has only arrows or lines pointing away from it, internal nodes have lines going to and from them, while leaf nodes only have lines pointing towards them. How to prune and evaluate the accuracy of decision trees is not shown here. If you are interested in this, please check out chapter 7 of @gries2021statistics which is a highly recommendable resource that provide a lot of additional information about decision trees and CARTs. Let us now go over the process by which the decision tree above is generated. In our example, we want to predict whether a person makes use of discourse like given their age, gender, and social status. In a first step, we load and inspect the data that we will use in this tutorial. # load data citdata &lt;- read.delim(&quot;https://slcladal.github.io/data/treedata.txt&quot;, header = T, sep = &quot;\\t&quot;) .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-b037290a{table-layout:auto;width:75%;}.cl-b03074ac{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b03074b6{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b0308a5a{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b030bc96{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b030bca0{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b030bcaa{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b030bcab{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b030bcac{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b030bcb4{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b030bcb5{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b030bcbe{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b030bcbf{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b030bcc8{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b030bcc9{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b030bcca{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.1: First 10 rows of the citdata data AgeGenderStatusLikeUser15-40femalehighno15-40femalehighno15-40malehighno41-80femalelowyes41-80malehighno41-80malelowno41-80femalelowyes15-40malehighno41-80malelowno41-80malelowno As tree-based models require either numeric or factorized data, we factorize the “character” variables in our data. # factorize variables (cit require factors instead of character vectors) citdata &lt;- citdata %&gt;% dplyr::mutate_if(is.character, factor) .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-b0500cc2{table-layout:auto;width:75%;}.cl-b049e41e{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b049e432{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b049f2ec{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b04a18a8{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b04a18b2{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b04a18bc{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b04a18bd{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b04a18be{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b04a18c6{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b04a18c7{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b04a18d0{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b04a18da{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b04a18db{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b04a18e4{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b04a18e5{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.2: First 10 rows of the factorized citdata data AgeGenderStatusLikeUser15-40femalehighno15-40femalehighno15-40malehighno41-80femalelowyes41-80malehighno41-80malelowno41-80femalelowyes15-40malehighno41-80malelowno41-80malelowno The data now consists of factors which two levels each. The first step in generating a decision tree consists in determining, what the root of the decision tree should be. This means that we have to determine which of the variables represents the root node. In order to do so, we tabulate for each variable level, how many speakers of that level have used discourse like (LikeUsers) and how many have not used discourse like (NonLikeUsers). # tabulate data table(citdata$LikeUser, citdata$Gender) ## ## female male ## no 43 75 ## yes 91 42 table(citdata$LikeUser, citdata$Age) ## ## 15-40 41-80 ## no 34 84 ## yes 92 41 table(citdata$LikeUser, citdata$Status) ## ## high low ## no 33 85 ## yes 73 60 None of the predictors is perfect (the predictors are therefore referred to as impure). To determine which variable is the root, we will calculate the degree of “impurity” for each variable - the variable which has the lowest impurity value will be the root. The most common measure of impurity in the context of conditional inference trees is called Gini (an alternative that is common when generating regression trees is the deviance). The Gini value or gini index was introduced by Corrado Gini as a measure for income inequality. In our case we seek to maximize inequality of distributions of leave nodes which is why the gini index is useful for tree based models. For each level we apply the following equation to determine the gini impurity value: \\[\\begin{equation} G_{x} = 1 - ( p_{1} )^{2} - ( p_{0} )^{2} \\end{equation}\\] For the node for men, this would mean the following: \\[\\begin{equation} G_{men} = 1-(\\frac{42} {42+75})^{2} - (\\frac{75} {42+75})^{2} = 0.4602235 \\end{equation}\\] For women, we calculate G or Gini as follows: \\[\\begin{equation} G_{women} = 1-(\\frac{91} {91+43})^{2} - (\\frac{43} {91+43})^{2} = 0.4358432 \\end{equation}\\] To calculate the Gini value of Gender, we need to calculate the weighted average leaf node impurity (weighted because the number of speakers is different in each group). We calculate the weighted average leaf node impurity using the equation below. \\[\\begin{equation} G_{Gender} = \\frac{N_{men}} {N_{Total}} \\times G_{men} + \\frac{N_{women}} {N_{Total}} \\times G_{women} G_{Gender} = \\frac{159} {303} \\times 0.4602235 + \\frac{144} {303} \\times 0.4358432 = 0.4611915 \\end{equation}\\] We will now perform the gini-calculation for gender (see below). # calculate Gini for men gini_men &lt;- 1-(42/(42+75))^2 - (75/(42+75))^2 # calculate Gini for women gini_women &lt;- 1-(91/(91+43))^2 - (43/(91+43))^2 # calculate weighted average of Gini for Gender gini_gender &lt;- 42/(42+75)* gini_men + 91/(91+43) * gini_women gini_gender ## [1] 0.4611915 The gini for gender is 0.4612. In a next step, we revisit the age distribution and we continue to calculate the gini value for age. # calculate Gini for age groups gini_young &lt;- 1-(92/(92+34))^2 - (34/(92+34))^2 # Gini: young gini_old &lt;- 1-(41/(41+84))^2 - (84/(41+84))^2 # Gini: old # calculate weighted average of Gini for Age gini_age &lt;- 92/(92+34)* gini_young + 41/(41+84) * gini_old gini_age ## [1] 0.4323148 The gini for age is .4323 and we continue by revisiting the status distribution and we continue to calculate the gini value for status. gini_high &lt;- 1-(73/(33+73))^2 - (33/(33+73))^2 # Gini: high gini_low &lt;- 1-(60/(60+85))^2 - (85/(60+85))^2 # Gini: low # calculate weighted average of Gini for Status gini_status &lt;- 73/(33+73)* gini_high + 60/(60+85) * gini_low gini_status ## [1] 0.4960521 The gini for status is .4961 and we can now compare the gini values for age, gender, and status. # compare age, gender, and status ginis gini_age; gini_gender; gini_status ## [1] 0.4323148 ## [1] 0.4611915 ## [1] 0.4960521 Since age has the lowest gini (impurity) value, our first split is by age and age, thus, represents our root node. Our manually calculated conditional inference tree right now looks as below. In a next step, we need to find out which of the remaining variables best separates the speakers who use discourse like from those that do not under the first node. In order to do so, we calculate the Gini values for Gender and SocialStatus for the 15-40 node. We thus move on and test if and how to split this branch. # 5TH NODE # split data according to first split (only young data) young &lt;- citdata %&gt;% dplyr::filter(Age == &quot;15-40&quot;) # inspect distribution tbyounggender &lt;- table(young$LikeUser, young$Gender) tbyounggender ## ## female male ## no 17 17 ## yes 58 34 # calculate Gini for Gender # calculate Gini for men gini_youngmen &lt;- 1-(tbyounggender[2,2]/sum(tbyounggender[,2]))^2 - (tbyounggender[1,2]/sum(tbyounggender[,2]))^2 # calculate Gini for women gini_youngwomen &lt;- 1-(tbyounggender[2,1]/sum(tbyounggender[,1]))^2 - (tbyounggender[1,1]/sum(tbyounggender[,1]))^2 # # calculate weighted average of Gini for Gender gini_younggender &lt;- sum(tbyounggender[,2])/sum(tbyounggender)* gini_youngmen + sum(tbyounggender[,1])/sum(tbyounggender) * gini_youngwomen gini_younggender ## [1] 0.3885714 The gini value for gender among young speakers is 0.3886. We continue by inspecting the status distribution. # calculate Gini for Status # inspect distribution tbyoungstatus &lt;- table(young$LikeUser, young$Status) tbyoungstatus ## ## high low ## no 11 23 ## yes 57 35 We now calculate the gini value for status. # calculate Gini for status # calculate Gini for low gini_younglow &lt;- 1-(tbyoungstatus[2,2]/sum(tbyoungstatus[,2]))^2 - (tbyoungstatus[1,2]/sum(tbyoungstatus[,2]))^2 # calculate Gini for high gini_younghigh &lt;- 1-(tbyoungstatus[2,1]/sum(tbyoungstatus[,1]))^2 - (tbyoungstatus[1,1]/sum(tbyoungstatus[,1]))^2 # # calculate weighted average of Gini for status gini_youngstatus &lt;- sum(tbyoungstatus[,2])/sum(tbyoungstatus)* gini_younglow + sum(tbyoungstatus[,1])/sum(tbyoungstatus) * gini_younghigh gini_youngstatus ## [1] 0.3666651 Since the gini value for status (0.3667) is lower than the gini value for gender (0.3886), we split by status. We would continue to calculate the gini values and always split at the lowest gini levels until we reach a leaf node. Then, we would continue doing the same for the remaining branches until the entire data is binned into different leaf nodes. In addition to plotting the decision tree, we can also check its accuracy. To do so, we predict the use of like based on the decision tree and compare them to the observed uses of like. Then we use the confusionMatrix function from the caret package to get an overview of the accuracy statistics. dtreeprediction &lt;- as.factor(ifelse(predict(dtree)[,2] &gt; .5, &quot;yes&quot;, &quot;no&quot;)) confusionMatrix(dtreeprediction, citdata$LikeUser) The conditional inference tree has an accuracy of 72.9 percent which is significantly better than the base-line accuracy of 53.0 percent (No Information Rate \\(*\\) 100). To understand what the other statistics refer to and how they are calculated, run the command ?confusionMatrix. 3.3 Splitting numeric, ordinal, and true categorical variables While it is rather straight forward to calculate the Gini values for categorical variables, it may not seem quite as apparent how to calculate splits for numeric or ordinal variables. To illustrate how the algorithm works on such variables, consider the example data set shown below. .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-b0c15fda{table-layout:auto;width:75%;}.cl-b0bb2746{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b0bb275a{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b0bb34b6{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b0bb34b7{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b0bb5770{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0bb577a{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0bb577b{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0bb5784{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0bb5785{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0bb5786{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0bb578e{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0bb578f{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.3: First 10 rows of the citdata2 data. AgeLikeUser15yes37no63no42yes22yes27yes In a first step, we order the numeric variable so that we arrive at the following table. .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-b0d5af12{table-layout:auto;width:75%;}.cl-b0cf7246{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b0cf7250{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b0cf820e{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b0cf8222{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b0cfa5a4{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0cfa5ae{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0cfa5af{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0cfa5b8{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0cfa5b9{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0cfa5ba{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0cfa5c2{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0cfa5c3{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.4: First 10 rows of the citdata2 data arranged by age. AgeLikeUser15yes22yes27yes37no42yes63no Next, we calculate the means for each level of “Age”. .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-b0eade32{table-layout:auto;width:75%;}.cl-b0e4d370{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b0e4d384{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b0e4e20c{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b0e4e216{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b0e50700{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0e5070a{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0e5070b{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0e50714{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0e5071e{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0e5071f{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0e50728{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0e50729{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.5: First 10 rows of the citdata3 data arranged by age. AgeLikeUser15.0yes18.522.0yes24.527.0yes32.037.0no39.542.0yes52.5 Now, we calculate the Gini values for each average level of age. How this is done is shown below for the first split. \\[\\begin{equation} G_{x} = 1 - ( p_{1} )^{2} - ( p_{0} )^{2} \\end{equation}\\] For an age smaller than 18.5 this would mean: \\[\\begin{equation} G_{youngerthan18.5} = 1-(\\frac{1} {1+0})^{2} - (\\frac{0} {1+0})^{2} = 0.0 \\end{equation}\\] For an age greater than 18.5, we calculate G or Gini as follows: \\[\\begin{equation} G_{olerthan18.5} = 1-(\\frac{2} {2+3})^{2} - (\\frac{3} {2+3})^{2} = 0.48 \\end{equation}\\] Now, we calculate the Gini for that split as we have done above. \\[\\begin{equation} G_{split18.5} = \\frac{N_{youngerthan18.5}} {N_{Total}} \\times G_{youngerthan18.5} + \\frac{N_{olderthan18.5}} {N_{Total}} \\times G_{olderthan18.5} G_{split18.5} = \\frac{1} {6} \\times 0.0 + \\frac{5} {6} \\times 0.48 = 0.4 \\end{equation}\\] We then have to calculate the gini values for all possible age splits which yields the following results: # 18.5 1-(1/(1+0))^2 - (0/(1+0))^2 1-(2/(2+3))^2 - (3/(2+3))^2 1/6 * 0.0 + 5/6 * 0.48 # 24.4 1-(2/(2+0))^2 - (0/(2+0))^2 1-(3/(3+1))^2 - (2/(3+1))^2 2/6 * 0.0 + 4/6 * 0.1875 # 32 1-(3/(3+0))^2 - (0/(3+0))^2 1-(1/(1+2))^2 - (2/(1+2))^2 3/6 * 0.0 + 3/6 * 0.4444444 # 39.5 1-(3/(3+1))^2 - (1/(3+1))^2 1-(1/(1+1))^2 - (1/(1+1))^2 4/6 * 0.375 + 2/6 * 0.5 # 52.5 1-(4/(4+1))^2 - (1/(4+1))^2 1-(0/(0+1))^2 - (1/(0+1))^2 5/6 * 0.32 + 1/6 * 0.0 .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-b103f32c{table-layout:auto;width:75%;}.cl-b0fca8a6{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b0fca8ba{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b0fcb6ca{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b0fcd678{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0fcd682{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0fcd68c{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0fcd68d{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0fcd696{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0fcd697{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0fcd6a0{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b0fcd6a1{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.6: First 10 rows of the citdata3 data with Gini coefficients. AgeSplitGini18.50.40024.50.50032.00.44439.50.41052.50.267 The split at 52.5 years of age has the lowest Gini value. Accordingly, we would split the data between speakers who are younger than 52.5 and speakers who are older than 52.5 years of age. The lowest Gini value for any age split would also be the Gini value that would be compared to other variables. The same procedure that we have used to determine potential splits for a numeric variable would apply to an ordinal variable with only two differences: The Gini values are calculated for the actual levels and not the means between variable levels. The Gini value is nor calculated for the lowest and highest level as the calculation of the Gini values is impossible for extreme values. Extreme levels can, therefore, not serve as a potential split location. When dealing with categorical variables with more than two levels, the situation is slightly more complex as we would also have to calculate the Gini values for combinations of variable levels. While the calculations are, in principle, analogous to the ones performed for binary of nominal categorical variables, we would also have to check if combinations would lead to improved splits. For instance, imagine we have a variable with categories A, B, and C. In such cases we would not only have to calculate the Gini scores for A, B, and C but also for A plus B, A plus C, and B plus C. Note that we ignore the combination A plus B plus C as this combination would include all other potential combinations. 3.4 Conditional Inference Trees Conditional Inference Trees (CITs) are much better at determining the true effect of a predictor, i.e. the effect of a predictor if all other effects are simultaneously considered. In contrast to CARTs, CITs use p-values to determine splits in the data. Below is a conditional inference tree which shows how and what factors contribute to the use of discourse like. In conditional inference trees predictors are only included if the predictor is significant (i.e. if these predictors are necessary). citdata &lt;- read.delim(&quot;https://slcladal.github.io/data/treedata.txt&quot;, header = T, sep = &quot;\\t&quot;) set.seed(111) # set.seed # apply bonferroni correction (1 minus alpha multiplied by n of predictors) control = ctree_control(mincriterion = 1-(.05*ncol(citdata)-1)) # convert character strings to factors citdata &lt;- citdata %&gt;% dplyr::mutate_if(is.character, factor) # create initial conditional inference tree model citd.ctree &lt;- partykit::ctree(LikeUser ~ Age + Gender + Status, data = citdata) plot(citd.ctree, gp = gpar(fontsize = 8)) # plot final ctree 3.4.1 Prettifying your CIT tree The easiest and most common way to visualize CITs is to simply use the plot function from base R. However, using this function does not allow to adapt and customize the visualization except for some very basic parameters. The ggparty function allows to use the ggplot syntax to customize CITs which allows more adjustments and is more aesthetically pleasing. To generate this customized CIT, we activate the ggparty package and extract the significant p-values from the CIT object. We then plot the CIT and define the nodes, edges, and text elements as shown below. # extract p-values pvals &lt;- unlist(nodeapply(citd.ctree, ids = nodeids(citd.ctree), function(n) info_node(n)$p.value)) pvals &lt;- pvals[pvals &lt;.05] # plotting ggparty(citd.ctree) + geom_edge() + geom_edge_label() + geom_node_label(line_list = list(aes(label = splitvar), aes(label = paste0(&quot;N=&quot;, nodesize, &quot;, p&quot;, ifelse(pvals &lt; .001, &quot;&lt;.001&quot;, paste0(&quot;=&quot;, round(pvals, 3)))), size = 10)), line_gpar = list(list(size = 13), list(size = 10)), ids = &quot;inner&quot;) + geom_node_label(aes(label = paste0(&quot;Node &quot;, id, &quot;, N = &quot;, nodesize)), ids = &quot;terminal&quot;, nudge_y = -0.0, nudge_x = 0.01) + geom_node_plot(gglist = list( geom_bar(aes(x = &quot;&quot;, fill = LikeUser), position = position_fill(), color = &quot;black&quot;), theme_minimal(), scale_fill_manual(values = c(&quot;gray50&quot;, &quot;gray80&quot;), guide = FALSE), scale_y_continuous(breaks = c(0, 1)), xlab(&quot;&quot;), ylab(&quot;Probability&quot;), geom_text(aes(x = &quot;&quot;, group = LikeUser, label = stat(count)), stat = &quot;count&quot;, position = position_fill(), vjust = 1.1)), shared_axis_labels = TRUE) We can also use position_dodge (instead of position_fill) to display frequencies rather than probabilities as shown below. # plotting ggparty(citd.ctree) + geom_edge() + geom_edge_label() + geom_node_label(line_list = list(aes(label = splitvar), aes(label = paste0(&quot;N=&quot;, nodesize, &quot;, p&quot;, ifelse(pvals &lt; .001, &quot;&lt;.001&quot;, paste0(&quot;=&quot;, round(pvals, 3)))), size = 10)), line_gpar = list(list(size = 13), list(size = 10)), ids = &quot;inner&quot;) + geom_node_label(aes(label = paste0(&quot;Node &quot;, id, &quot;, N = &quot;, nodesize)), ids = &quot;terminal&quot;, nudge_y = 0.01, nudge_x = 0.01) + geom_node_plot(gglist = list( geom_bar(aes(x = &quot;&quot;, fill = LikeUser), position = position_dodge(), color = &quot;black&quot;), theme_minimal(), theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()), scale_fill_manual(values = c(&quot;gray50&quot;, &quot;gray80&quot;), guide = FALSE), scale_y_continuous(breaks = seq(0, 100, 20), limits = c(0, 100)), xlab(&quot;&quot;), ylab(&quot;Frequency&quot;), geom_text(aes(x = &quot;&quot;, group = LikeUser, label = stat(count)), stat = &quot;count&quot;, position = position_dodge(0.9), vjust = -0.7)), shared_axis_labels = TRUE) 3.4.2 Problems of Conditional Inference Trees Like other tree-based methods, CITs are very intuitive, multivariate, non-parametric, they do not require large data sets, and they are easy to implement. Despite these obvious advantages, they have at least one major short coming compared to other, more sophisticated tree-structure models (in addition to the general issues that tree-structure models exhibit as discussed in the section Tree-Structure Model Basics): they are prone to overfitting which means that they fit the observed data very well but preform much worse when being applied to new data. An extension which remedies this problem is to use a so-called ensemble method which grows many varied trees. The most common ensemble method is called a Random Forest Analysis and will have a look at how Random Forests work and how to implement them in R in the next section. 3.5 Random Forests Random Forests (RFs) are an extension of Conditional Inference Trees [@breiman2001random]. Like Conditional Inference Trees, Random Forests represent a multivariate, non-parametric partitioning method that is particularly useful when dealing with relatively small sample sizes and many predictors (including interactions) and they are insensitive to multicollinearity (if two predictors strongly correlate with the dependent variable AND are highly correlated or collinear, RFs will report both variables as highly important - the ordering in which they were included into the model is irrelevant). The latter point is a real advantage over regression models in particular. Also, RFs outperform CITs in that they are substantially less prone to overfitting and they perform much better when applied to new data. However, random forests have several issues: RFs only show variable importance but not if the variable is positively or negatively correlated with the dependent variable; RFs do not report if a variable is important as a main effect or as part of an interactions RFs do not indicate in which significant interactions a variable is involved. Therefore, Random Forest analyses are ideal for classification, imputing missing values, and - though to a lesser degree - as a variable selection procedure but they do not lend themselves for drawing inferences about the relationships of predictors and dependent variables. Bootstrapped Data Random Forests do not work on one-and-the-same data set (as CITs do) but in Random Forest analyses, many samples (with replacement) are drawn from the original data set. This generation of new data set based on an existing data set is called “bootstrapping”. Bootstrapping allows us to produce many trees based on variations of the original data set rather than dealing with only a single, fixed data set that would produce only a single tree. Therefore, because the data is different each time, the individual CITs are also different. Imagine, we are dealing with a very small data set to which we want to apply a Random Forest Analysis. The original data set is displayed below. .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-b356e2d8{table-layout:auto;width:75%;}.cl-b346fba2{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b346fbac{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b3471376{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b3471380{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b34871c6{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b34871d0{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b34871da{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b34871db{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b34871e4{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b34871e5{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b34871ee{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b34871f8{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b34871f9{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b34871fa{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3487202{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3487203{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.7: First 10 rows of the citdata data. IdAgeGenderStatusLikeUser115-40femalehighno215-40femalehighno315-40malehighno441-80femalelowyes541-80malehighno641-80malelowno741-80femalelowyes815-40malehighno941-80malelowno1041-80malelowno1115-40femalelowyes1241-80malelowno1315-40malelowyes1441-80femalelowno1515-40femalelowyes1641-80malehighno1715-40femalehighyes1815-40malehighyes1941-80malehighno2041-80malelowno2115-40femalelowyes2215-40malelowno2315-40femalelowyes2415-40malelowyes2541-80malelowyes2615-40femalelowyes2741-80femalelowno2815-40femalehighyes2941-80femalehighyes3041-80malehighno3115-40femalelowno3215-40malelowyes3341-80femalelowno3415-40malehighyes3541-80malelowno3615-40femalelowno3741-80femalelowyes3815-40malehighyes3941-80malelowno4015-40malehighyes4115-40femalelowno4241-80malehighno4341-80femalelowyes4441-80femalelowyes4515-40malehighyes4615-40femalehighyes4715-40malelowyes4815-40femalehighyes4941-80malelowno5041-80malelowno5141-80malelowno5215-40femalelowyes5315-40malehighyes5415-40femalelowyes5541-80femalelowyes5615-40femalehighyes5741-80femalehighyes5815-40femalelowyes5941-80malelowno6015-40femalehighyes6141-80malehighno6215-40femalelowyes6315-40femalelowyes6441-80malelowno6515-40femalehighyes6641-80femalelowno6715-40femalehighyes6841-80femalelowno6915-40malehighyes7015-40malehighyes7115-40femalehighyes7215-40malehighno7341-80malelowno7441-80femalelowno7541-80malelowno7641-80femalehighyes7741-80malelowno7815-40femalelowno7915-40femalehighyes8015-40femalelowno8141-80malelowno8215-40femalehighyes8341-80femalelowyes8415-40femalelowyes8515-40malehighyes8641-80femalelowyes8741-80femalelowno8815-40malelowno8915-40malehighyes9041-80femalehighyes9115-40malelowyes9241-80malelowno9315-40femalelowno9441-80malehighno9541-80malehighyes9615-40malehighno9715-40malelowno9815-40malelowno9941-80malelowno10015-40femalelowyes10141-80femalehighno10241-80femalelowyes10315-40femalehighyes10441-80femalehighyes10515-40malelowyes10641-80malehighno10715-40femalelowyes10815-40malelowyes10915-40malehighyes11015-40malelowyes11141-80femalelowyes11215-40femalehighyes11341-80femalelowyes11441-80femalelowno11541-80malelowno11615-40femalehighyes11715-40femalehighyes11841-80femalelowyes11941-80malelowno12041-80malehighno12115-40femalehighyes12215-40malehighyes12315-40malelowyes12441-80femalehighyes12541-80femalelowno12641-80malehighno12741-80femalelowno12841-80femalehighyes12941-80femalelowyes13041-80malelowno13115-40femalelowyes13241-80malelowno13341-80malelowno13415-40femalehighyes13515-40malelowyes13615-40femalehighno13715-40malelowyes13841-80malelowyes13941-80malehighno14041-80malelowno14115-40malehighyes14241-80femalehighyes14341-80femalelowyes14441-80femalelowno14541-80malelowno14615-40malehighyes14715-40malelowno14815-40malelowno14941-80femalelowno15015-40femalehighyes15115-40femalelowno15241-80femalehighno15341-80malelowno15415-40femalehighyes15541-80malelowyes15641-80malelowno15715-40femalelowno15841-80femalelowyes15915-40femalehighyes16015-40femalehighyes16141-80femalelowno16241-80malelowno16341-80femalelowno16415-40femalelowno16515-40femalehighyes16615-40femalelowyes16715-40femalehighyes16841-80malehighno16941-80femalehighyes17041-80malehighno17115-40femalelowno17215-40malelowno17341-80malelowno17441-80femalelowyes17515-40femalelowno17641-80femalehighno17715-40malelowno17841-80femalelowno17915-40femalelowno18015-40femalehighyes18115-40femalehighyes18241-80femalehighno18315-40malehighno18415-40femalehighyes18541-80femalelowyes18641-80malehighno18741-80malehighyes18841-80malelowno18915-40malehighno19015-40femalehighyes19115-40malehighyes19215-40femalehighyes19341-80malehighyes19441-80malehighno19515-40malelowyes19641-80femalelowno19741-80malelowno19841-80malelowno19915-40femalelowyes20041-80malehighyes20141-80femalelowyes20215-40femalehighyes20341-80malelowno20415-40femalelowyes20515-40malelowyes20615-40femalelowyes20715-40malehighyes20841-80malehighno20941-80malelowno21041-80malelowno21115-40malehighyes21215-40malehighyes21315-40femalehighyes21415-40malelowno21541-80femalehighyes21641-80femalelowno21741-80femalelowyes21815-40femalehighyes21941-80femalelowno22015-40femalehighyes22115-40malelowyes22215-40femalehighno22341-80malelowno22441-80malelowno22541-80malehighyes22615-40femalehighyes22741-80malehighno22841-80malelowno22915-40femalelowyes23015-40femalelowyes23141-80femalelowno23215-40femalehighyes23315-40femalehighyes23415-40femalelowyes23541-80femalelowyes23641-80femalelowno23741-80malelowno23841-80femalehighyes23915-40malelowno24041-80femalelowyes24141-80malelowno24215-40malehighno24341-80malelowno24415-40femalehighyes24541-80femalehighno24615-40femalelowno24741-80femalelowyes24815-40malehighyes24941-80femalelowno25015-40femalehighyes25115-40malehighyes We now draw a sample from this data set and receive the following data set. ## Id Age Gender Status LikeUser ## 1 6 41-80 male low no ## 2 3 15-40 male high no ## 3 4 41-80 female low yes ## 4 1 15-40 female high no ## 5 2 15-40 female high no ## 6 2 15-40 female high no As you can see, the bootstrapped data contains the second row twice while the fifth row is missing. 3.5.1 Out-Of-Bag data Because the data is reshuffled for every new tree, a part of the data (on average about 30%) remains unused for a given tree. The data that is not used is called Out-Of-Bag data or OOB. The OOB is important because the quality of the overall performance of the random forest can be assessed by applying the resulting tree-model to the data that it was not fit to. The quality of that tree is then measured in the OOB error, which is the error rate of the respective tree if applied to the OOB data. 3.5.2 Random Variable Selection Random Forests also differ from simple CITs in that at each step, not all possible variables are considered for a node, but only a subset. For example, we have a data set with five predicting independent variables and one dependent variable. When generating a CIT, all possible variables (variables that do not represent a node further up in the tree) are considered as splitting candidates. In Random Forests, only a fixed number (typically the square-root of the number of independent variables) are considered as candidates for a node. So, at each potential split, a fixed number of randomly selected variables is considered potential node candidates. 3.6 Random Forests in R This section shows how a Random Forest Analysis can be implemented in R. Ina first step, we load and inspect the data. # load random forest data rfdata &lt;- read.delim(&quot;https://slcladal.github.io/data/mblrdata.txt&quot;, header = T, sep = &quot;\\t&quot;) .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-b3f31a0e{table-layout:auto;width:75%;}.cl-b3eb27ea{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b3eb27f4{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b3eb35d2{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b3eb35d3{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b3eb649e{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3eb64a8{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3eb64b2{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3eb64b3{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3eb64bc{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3eb64bd{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3eb64be{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3eb64c6{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3eb64c7{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3eb64c8{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3eb64d0{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b3eb64d1{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.8: First 10 rows of the rfdata data. IDGenderAgeConversationTypePrimingSUFlikeS1A-061$CWomenYoungMixedGenderNoPrime0S1A-023$BWomenYoungMixedGenderNoPrime0S1A-054$AWomenYoungSameGenderNoPrime0S1A-090$BWomenYoungMixedGenderNoPrime0S1A-009$BWomenOldSameGenderPrime0S1A-085$EMenYoungMixedGenderPrime1S1A-003$CWomenYoungMixedGenderNoPrime1S1A-084$CWomenYoungSameGenderNoPrime0S1A-076$AWomenYoungSameGenderNoPrime0S1A-083$DMenOldMixedGenderNoPrime1 The data consists of four categorical variables (Gender, Age, ConversationType, and SUFlike). Our dependent variable is SUFlike which stands for speech-unit final like (a pragmatic marker that is common in Irish English and is used as in A wee girl of her age, like). While Age and Gender are pretty straight forward what they are called, ConversationType encodes whether a conversation has taken place between interlocutors of the same or of different genders. Before going any further, we need to factorize the variables as tree-based models require factors instead of character variables (but they can, of course, handle numeric and ordinal variables). In addition, we will check if the data contains missing values (NAs; NA stands for not available). # factorize variables (rf require factors instead of character vectors) rfdata &lt;- rfdata %&gt;% dplyr::mutate_if(is.character, factor) %&gt;% dplyr::select(-ID) .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-b40d0004{table-layout:auto;width:75%;}.cl-b4053d6a{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b4053d74{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-b4054b8e{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b4054b8f{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-b4057dd4{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b4057de8{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b4057de9{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b4057df2{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b4057df3{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b4057df4{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b4057dfc{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b4057e06{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b4057e07{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b4057e08{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b4057e10{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-b4057e11{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.9: First 10 rows of the factorized rfdata data. GenderAgeConversationTypePrimingSUFlikeWomenYoungMixedGenderNoPrime0WomenYoungMixedGenderNoPrime0WomenYoungSameGenderNoPrime0WomenYoungMixedGenderNoPrime0WomenOldSameGenderPrime0MenYoungMixedGenderPrime1WomenYoungMixedGenderNoPrime1WomenYoungSameGenderNoPrime0WomenYoungSameGenderNoPrime0MenOldMixedGenderNoPrime1 We now check if the data contains missing values and remove those (if necessary). # check for NAs natest &lt;- rfdata %&gt;% na.omit() nrow(natest) # no NAs present in data (same number of rows with NAs omitted) ## [1] 2000 In our case, the data does not contain missing values. Random Forests offer a very nice way to deal with missing data though. If NAs are present, they can either be deleted OR their values for any missing values can be imputed using proximities. In this way, such data points do not have to be removed which can be problematic especially when dealing with relatively small data sets. For imputing values, you could run the code below but as our data does not have NAs, we will skip this step and just show it here so you can have a look at how it is done. # replacing NAs with estimates data.imputed &lt;- rfImpute(SUFlike ~ ., data = rfdata, iter=6) The argument iter refers to the number of iterations to run. According to [@breiman2001random], 4 to 6 iterations is usually good enough. With this data set (if it had NAs) and when we were to execute the code, the resulting OOB-error rates lie somewhere around 17 and 18 percent. When we were to set iter to 20, we get values a little better and a little worse, so doing more iterations doesn’t improve the situation. Also, if you want to customize the rfImpute function, you can change the number of trees it uses (the default is 300) and the number of variables that it will consider at each step. We will now generate a first random forest object and inspect its model fit. As random forests rely on re-sampling, we set a seed so that we arrive at the same estimations. # set.seed set.seed(2019120204) # create initial model rfmodel1 &lt;- cforest(SUFlike ~ ., data = rfdata, controls = cforest_unbiased(ntree = 50, mtry = 3)) # evaluate random forest (model diagnostics) rfmodel1_pred &lt;- unlist(party::treeresponse(rfmodel1))#[c(FALSE,TRUE)] somers2(rfmodel1_pred, as.numeric(rfdata$SUFlike)) ## C Dxy n Missing ## 0.7112131 0.4224262 2000.0000000 0.0000000 The model parameters are excellent: remember that if the C-value is 0.5, the predictions are random, while the predictions are perfect if the C-value is 1. C-values above 0.8 indicate real predictive capacity [@baayen2008analyzing 204]. Somers’ Dxy is a value that represents a rank correlation between predicted probabilities and observed responses. Somers’ Dxy values range between 0, which indicates complete randomness, and 1, which indicates perfect prediction [@baayen2008analyzing 204]. In a next step, we extract the variable importance (conditional=T adjusts for correlations between predictors). # extract variable importance based on mean decrease in accuracy rfmodel1_varimp &lt;- varimp(rfmodel1, conditional = T) # show variable importance rfmodel1_varimp ## Gender Age ConversationType Priming ## 0.003770260 0.000542920 0.002520164 0.022095496 We can also calculate more robust variable importance using the varimpAUC function from the party package which calculates importance statistics that are corrected towards class imbalance, i.e. differences in the number of instances per category. The variable importance is easily visualized using the dotplot function from base R. # extract more robust variable importance rfmodel1_robustvarimp &lt;- party::varimp(rfmodel1) # plot result dotchart(sort(rfmodel1_robustvarimp), pch = 20, main = &quot;Conditional importance of variables&quot;) The plot shows that Age is the most important predictor and that Priming is not really important as a predictor for speech-unit final like. Gender and ConversationType are equally important but both much less so than Age. We will now use an alternative way to calculate RFs which allows us to use different diagnostics and pruning techniques by using the randomForest rather than the cforest function. A few words on the parameters of the randomForest function: if the thing we’re trying to predict is a numeric variable, the randomForest function will set mtry (the number of variables considered at each step) to the total number of variables divided by 3 (rounded down), or to 1 if the division results in a value less than 1. If the thing we’re trying to predict is a “factor” (i.e. either “yes/no” or “ranked”), then randomForest() will set mtry to the square root of the number of variables (rounded down to the next integer value).Again, we start by setting a seed to store random numbers and thus make results reproducible. # set.seed set.seed(2019120205) rfmodel2 &lt;- randomForest::randomForest(SUFlike ~ ., data=rfdata, mtry = 2, proximity=TRUE) # inspect model rfmodel2 ## ## Call: ## randomForest(formula = SUFlike ~ ., data = rfdata, mtry = 2, proximity = TRUE) ## Type of random forest: regression ## Number of trees: 500 ## No. of variables tried at each split: 2 ## ## Mean of squared residuals: 0.1277716 ## % Var explained: 10.28 The output tells us that the model explains less than 15 percent of the variance. It is recommendable to check if changing parameters causes and increase in the amount of variance that is explained by a model (which is desirable). In this case, we can try different values for mtry and for ntree as shown below and then compare the performance of the random forest models by inspecting the amount of variance that they explain. Again, we begin by setting a seed and then continue by specifying the random forest model. # set.seed (to store random numbers and thus make results reproducible) set.seed(2019120206) # create a new model with fewer trees and that takes 2 variables at a time rfmodel3 &lt;- randomForest(SUFlike ~ ., data=rfdata, ntree=30, mtry = 4, proximity=TRUE) # inspect model rfmodel3 ## ## Call: ## randomForest(formula = SUFlike ~ ., data = rfdata, ntree = 30, mtry = 4, proximity = TRUE) ## Type of random forest: regression ## Number of trees: 30 ## No. of variables tried at each split: 4 ## ## Mean of squared residuals: 0.1283899 ## % Var explained: 9.85 Despite optimization, the results have not changed but it may be very useful for other data. To evaluate the tree, we create a confusion matrix. # save what the model predicted in a new variable rfdata$Probability &lt;- predict(rfmodel3, rfdata) rfdata$Prediction &lt;- ifelse(rfdata$Probability &gt;=.5, 1, 0) # create confusion matrix to check accuracy confusionMatrix(as.factor(rfdata$Prediction), as.factor(rfdata$SUFlike)) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 0 1 ## 0 1622 297 ## 1 34 47 ## ## Accuracy : 0.8345 ## 95% CI : (0.8175, 0.8505) ## No Information Rate : 0.828 ## P-Value [Acc &gt; NIR] : 0.2303 ## ## Kappa : 0.1665 ## ## Mcnemar&#39;s Test P-Value : &lt;2e-16 ## ## Sensitivity : 0.9795 ## Specificity : 0.1366 ## Pos Pred Value : 0.8452 ## Neg Pred Value : 0.5802 ## Prevalence : 0.8280 ## Detection Rate : 0.8110 ## Detection Prevalence : 0.9595 ## Balanced Accuracy : 0.5580 ## ## &#39;Positive&#39; Class : 0 ## The RF performs significantly better than a no-information base-line model but the base-line model already predicts 78.18 percent of cases correctly (compared to the RF with a prediction accuracy of 82.5 percent). Unfortunately, we cannot easily compute robust variable importance for RF models nor C or Somers’ Dxy which is why it is advisable to create analogous models using both the cforest and the randomForest functions. In a last step, we can now visualize the results of the optimized RF. # plot variable importance varImpPlot(rfmodel3, main = &quot;&quot;, pch = 20) Here is an alternative way of plotting variable importance using the vip function from the vip package. # generate vip plot vip::vip(rfmodel3, geom = &quot;point&quot;, horizontal = FALSE) Using the vip package, you can also generate variable importance barplots. # generate vip plot vip::vip(rfmodel3, horizontal = FALSE) A second type of visualization that can provide insights in the partial function from the pdp package which shows the effects of individual predictors - but remember that this still does not provide information about the way that the predictor interacts with other predictors. # extract importance of individual variables rfmodel3 %&gt;% # the %&gt;% operator is read as &quot;and then&quot; partial(pred.var = &quot;Age&quot;) %&gt;% autoplot(smooth = TRUE, ylab = expression(f(Age))) + theme_light() + ggtitle(&quot;Partial Depencence Plot: Age&quot;) + ylim(-20, 0) You can however use the partial function to show how the effect of predictors interacts with other predictors (see below). partial(rfmodel3, pred.var = c(&quot;Age&quot;, &quot;Gender&quot;), plot = TRUE, plot.engine = &quot;ggplot2&quot;) Another common way to evaluate the performance of RFs is to split the data into a test and a training set. the model is then fit to the training set and, after that, applied to the test set. This allows us to evaluate how well the RF performs on data that it was not trained on. This approach is particularly common in machine learning contexts. 3.7 Boruta Boruta [@kursa2010feature] is a variable selection procedure and it represents an extension of random forest analyses [@breiman2001random]. The name Boruta is derived from a demon in Slavic mythology who dwelled in pine forests. Boruta is an alternative to regression modeling that is better equipped to handle small data sets because it uses a distributional approach during which hundreds of (random) forests are grown from permuted data sets. Boruta outperforms random forest analyses because: Boruta does not provide merely a single value for each predictor but a distribution of values leading to higher reliability. Boruta provides definitive cut-off points for variables that have no meaningful relationship with the dependent variable. This is a crucial difference between RF and Boruta that make Boruta particularly interesting from a variable selection point of view. The Boruta procedure consists out of five steps. In a first step, the Boruta algorithm copies the data set and adds randomness to the data by (re-)shuffling data points and thereby creating randomized variables. These randomized variables are referred to as shadow features. Secondly, a random forest classifier is trained on the extended data set. In a third step, a feature importance measure (Mean Decrease Accuracy represented by z-scores) is calculated to determine the relative importance of all predictors (both original or real variables and the randomized shadow features). In the next step, it is checked at each iteration of the process whether a real predictor has a higher importance compared with the best shadow feature. The algorithm keeps track of the performance of the original variables by storing whether they outperformed the best shadow feature or not in a vector. In the fifth step, predictors that did not outperform the best shadow feature are removed and the process continues without them. After a set number of iterations, or if all the variables have been either confirmed as outperforming the best shadow feature, the algorithm stops. Despite its obvious advantages of Boruta over random forest analyses and regression modeling, it can neither handle multicollinearity not hierarchical data structures where data points are nested or grouped by a given predictor (as is the case in the present analysis as data points are grouped by adjective type). As Boruta is a variable selection procedure, it is also limited in the sense that it provides information on which predictors to include and how good these predictors are (compared to the shadow variables) while it is neither able to take hierarchical data structure into account, nor does it provide information about how one level of a factor compares to other factors. In other words, Boruta shows that a predictor is relevant and how strong it is but it does not provide information on how the likelihood of an outcome being used differs between variable levels, for instance between men and women. 3.7.1 Boruta in R We begin by loading and inspecting the data. # load data borutadata &lt;- read.delim(&quot;https://slcladal.github.io/data/ampaus05_statz.txt&quot;, header = T, sep = &quot;\\t&quot;) .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-bc2f1cfe{table-layout:auto;width:75%;}.cl-bc27e010{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-bc27e01a{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-bc27f096{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-bc27f097{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-bc283524{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc28352e{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc28352f{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc283538{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc283539{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc28353a{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc283542{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc283543{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc283544{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc28354c{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc28354d{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc283556{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc283557{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc283560{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc283561{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc283562{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.10: First 10 rows of the borutadata data. AgeAdjectiveFileSpeakerFunctionPrimingGenderOccupationConversationTypeAudienceSizeveryreallyFreqGradabiltySemanticCategoryEmotionality26-40good&lt;S1A-001:1$B&gt;AttributiveNoPrimeMenAcademicManagerialProfessionalsSameSexMultipleInterlocutors0027.84810NotGradableValuePositiveEmotional26-40good&lt;S1A-001:1$B&gt;AttributiveNoPrimeMenAcademicManagerialProfessionalsSameSexMultipleInterlocutors0027.84810NotGradableValuePositiveEmotional26-40good&lt;S1A-001:1$B&gt;PredicativeNoPrimeMenAcademicManagerialProfessionalsSameSexMultipleInterlocutors0027.84810NotGradableValuePositiveEmotional17-25nice&lt;S1A-003:1$B&gt;AttributiveNoPrimeMenAcademicManagerialProfessionalsSameSexDyad107.29282NotGradableHumanPropensityNonEmotional41-80other&lt;S1A-003:1$A&gt;PredicativeNoPrimeMenAcademicManagerialProfessionalsSameSexDyad000.61728NotGradableValueNonEmotional41-80other&lt;S1A-004:1$C&gt;PredicativeNoPrimeMenMixedSexMultipleInterlocutors102.46914NotGradableValuePositiveEmotional41-80good&lt;S1A-004:1$B&gt;AttributiveNoPrimeWomenAcademicManagerialProfessionalsMixedSexMultipleInterlocutors0020.98765NotGradableValuePositiveEmotional41-80other&lt;S1A-005:1$B&gt;PredicativeNoPrimeWomenMixedSexMultipleInterlocutors100.61728GradabilityUndeterminedHumanPropensityNegativeEmotional17-25other&lt;S1A-006:1$B&gt;AttributiveNoPrimeMenAcademicManagerialProfessionalsMixedSexMultipleInterlocutors014.64088GradabilityUndeterminedDimensionNonEmotional17-25other&lt;S1A-006:1$B&gt;AttributivePrimeMenAcademicManagerialProfessionalsMixedSexMultipleInterlocutors010.44199NotGradablePhysicalPropertyNonEmotional As the data contains non-factorized character variables, we convert those into factors. # factorize variables (boruta - like rf - require factors instead of character vectors) borutadata &lt;- borutadata %&gt;% dplyr::filter(complete.cases(.)) %&gt;% dplyr::mutate_if(is.character, factor) .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-bc4fc724{table-layout:auto;width:75%;}.cl-bc48d216{font-family:'Arial';font-size:12pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-bc48d220{font-family:'Arial';font-size:12pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-bc48e080{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-bc48e08a{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-bc492432{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc49243c{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc49243d{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc492446{background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc492447{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc492448{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc492450{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc49245a{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc49245b{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc492464{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc492465{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc492466{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc492467{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc49246e{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc49246f{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 1pt solid rgba(102, 102, 102, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-bc492470{background-color:rgba(207, 207, 207, 1.00);vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 1pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.11: First 10 rows of the factorized borutadata data. AgeAdjectiveFileSpeakerFunctionPrimingGenderOccupationConversationTypeAudienceSizeveryreallyFreqGradabiltySemanticCategoryEmotionality26-40good&lt;S1A-001:1$B&gt;AttributiveNoPrimeMenAcademicManagerialProfessionalsSameSexMultipleInterlocutors0027.84810NotGradableValuePositiveEmotional26-40good&lt;S1A-001:1$B&gt;AttributiveNoPrimeMenAcademicManagerialProfessionalsSameSexMultipleInterlocutors0027.84810NotGradableValuePositiveEmotional26-40good&lt;S1A-001:1$B&gt;PredicativeNoPrimeMenAcademicManagerialProfessionalsSameSexMultipleInterlocutors0027.84810NotGradableValuePositiveEmotional17-25nice&lt;S1A-003:1$B&gt;AttributiveNoPrimeMenAcademicManagerialProfessionalsSameSexDyad107.29282NotGradableHumanPropensityNonEmotional41-80other&lt;S1A-003:1$A&gt;PredicativeNoPrimeMenAcademicManagerialProfessionalsSameSexDyad000.61728NotGradableValueNonEmotional41-80good&lt;S1A-004:1$B&gt;AttributiveNoPrimeWomenAcademicManagerialProfessionalsMixedSexMultipleInterlocutors0020.98765NotGradableValuePositiveEmotional17-25other&lt;S1A-006:1$B&gt;AttributiveNoPrimeMenAcademicManagerialProfessionalsMixedSexMultipleInterlocutors014.64088GradabilityUndeterminedDimensionNonEmotional17-25other&lt;S1A-006:1$B&gt;AttributivePrimeMenAcademicManagerialProfessionalsMixedSexMultipleInterlocutors010.44199NotGradablePhysicalPropertyNonEmotional17-25other&lt;S1A-006:1$B&gt;PredicativePrimeMenAcademicManagerialProfessionalsMixedSexMultipleInterlocutors010.44199NotGradablePhysicalPropertyNonEmotional17-25nice&lt;S1A-007:1$A&gt;AttributiveNoPrimeWomenAcademicManagerialProfessionalsSameSexDyad017.29282NotGradableHumanPropensityNonEmotional We can now create our initial Boruta model and set a seed for reproducibility. # set.seed set.seed(2019120207) # initial run boruta1 &lt;- Boruta(really~.,data=borutadata) print(boruta1) ## Boruta performed 99 iterations in 2.868931 secs. ## 8 attributes confirmed important: Adjective, AudienceSize, ConversationType, Emotionality, FileSpeaker and 3 more; ## 5 attributes confirmed unimportant: Age, Gender, Gradabilty, Occupation, Priming; ## 1 tentative attributes left: SemanticCategory; # extract decision getConfirmedFormula(boruta1) ## really ~ Adjective + FileSpeaker + Function + ConversationType + ## AudienceSize + very + Freq + Emotionality ## &lt;environment: 0x000001294bce6b78&gt; In a next step, we inspect the history to check if any of the variables shows drastic fluctuations in their importance assessment. plotImpHistory(boruta1) The fluctuations are do not show clear upward or downward trends (which what we want). If predictors do perform worse than the shadow variables, then these variables should be excluded and the Boruta analysis should be re-run on the data set that does no longer contain the superfluous variables. Tentative variables can remain but they are unlikely to have any substantial effect. We thus continue by removing variables that were confirmed as being unimportant, then setting a new seed, re-running the Boruta on the reduced data set, and again inspecting the decisions. # remove irrelevant variables rejected &lt;- names(boruta1$finalDecision)[which(boruta1$finalDecision == &quot;Rejected&quot;)] # update data for boruta borutadata &lt;- borutadata %&gt;% dplyr::select(-rejected) # set.seed (to store random numbers and thus make results reproducible) set.seed(2019120208) # 2nd run boruta2 &lt;- Boruta(really~.,data=borutadata) print(boruta2) ## Boruta performed 99 iterations in 2.850794 secs. ## 8 attributes confirmed important: Adjective, AudienceSize, ConversationType, Emotionality, FileSpeaker and 3 more; ## No attributes deemed unimportant. ## 1 tentative attributes left: SemanticCategory; # extract decision getConfirmedFormula(boruta2) ## really ~ Adjective + FileSpeaker + Function + ConversationType + ## AudienceSize + very + Freq + Emotionality ## &lt;environment: 0x000001292dd25288&gt; Only adjective frequency and adjective type are confirmed as being important while all other variables are considered tentative. However, no more variables need to be removed as all remaining variables are not considered unimportant. In a last step, we visualize the results of the Boruta analysis. borutadf &lt;- as.data.frame(boruta2$ImpHistory) %&gt;% tidyr::gather(Variable, Importance, Adjective:shadowMin) %&gt;% dplyr::mutate(Type = ifelse(str_detect(Variable, &quot;shadow&quot;), &quot;Control&quot;, &quot;Predictor&quot;)) %&gt;% dplyr::mutate(Type = factor(Type), Variable = factor(Variable)) ggplot(borutadf, aes(x = reorder(Variable, Importance, mean), y = Importance, fill = Type)) + geom_boxplot() + geom_vline(xintercept=3.5, linetype=&quot;dashed&quot;, color = &quot;black&quot;) + scale_fill_manual(values = c(&quot;gray80&quot;, &quot;gray40&quot;)) + theme_bw() + theme(legend.position = &quot;top&quot;, axis.text.x = element_text(angle=90)) + labs(x = &quot;Variable&quot;) Of the remaining variables, adjective frequency and adjective type have the strongest effect and are confirmed as being important while syntactic function fails to perform better than the best shadow variable. All other variables have only a marginal effect on the use of really as an adjective amplifier. sessionInfo() ## R version 4.2.0 (2022-04-22 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19043) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_Australia.utf8 LC_CTYPE=English_Australia.utf8 LC_MONETARY=English_Australia.utf8 ## [4] LC_NUMERIC=C LC_TIME=English_Australia.utf8 ## ## attached base packages: ## [1] stats4 grid stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] flextable_0.7.1 vip_0.3.2 RCurl_1.98-1.6 pdp_0.8.0 randomForest_4.7-1.1 party_1.3-10 ## [7] strucchange_1.5-2 sandwich_3.0-1 zoo_1.8-10 modeltools_0.2-23 Hmisc_4.7-0 Formula_1.2-4 ## [13] survival_3.3-1 Gmisc_3.0.0 htmlTable_2.4.0 Rcpp_1.0.8.3 ggparty_1.0.0 partykit_1.2-15 ## [19] mvtnorm_1.1-3 libcoin_1.0-9 forcats_0.5.1 stringr_1.4.0 purrr_0.3.4 readr_2.1.2 ## [25] tibble_3.1.7 tidyverse_1.3.1 cowplot_1.1.1 caret_6.0-92 lattice_0.20-45 ggplot2_3.3.6 ## [31] tree_1.0-41 Boruta_7.0.0 here_1.0.1 tidyr_1.2.0 dplyr_1.0.9 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.4.0 uuid_1.1-0 backports_1.4.1 systemfonts_1.0.4 plyr_1.8.7 splines_4.2.0 ## [7] listenv_0.8.0 TH.data_1.1-1 digest_0.6.29 foreach_1.5.2 htmltools_0.5.2 fansi_1.0.3 ## [13] magrittr_2.0.3 checkmate_2.1.0 cluster_2.1.3 tzdb_0.3.0 recipes_0.2.0 globals_0.15.0 ## [19] modelr_0.1.8 gower_1.0.0 matrixStats_0.62.0 officer_0.4.2 hardhat_1.0.0 jpeg_0.1-9 ## [25] colorspace_2.0-3 rvest_1.0.2 haven_2.5.0 xfun_0.31 crayon_1.5.1 jsonlite_1.8.0 ## [31] iterators_1.0.14 glue_1.6.2 gtable_0.3.0 ipred_0.9-12 future.apply_1.9.0 abind_1.4-5 ## [37] scales_1.2.0 DBI_1.1.2 proxy_0.4-26 foreign_0.8-82 lava_1.6.10 prodlim_2019.11.13 ## [43] htmlwidgets_1.5.4 httr_1.4.3 RColorBrewer_1.1-3 ellipsis_0.3.2 farver_2.1.0 pkgconfig_2.0.3 ## [49] XML_3.99-0.9 nnet_7.3-17 sass_0.4.1 dbplyr_2.1.1 utf8_1.2.2 labeling_0.4.2 ## [55] tidyselect_1.1.2 rlang_1.0.2 reshape2_1.4.4 munsell_0.5.0 cellranger_1.1.0 tools_4.2.0 ## [61] cli_3.3.0 generics_0.1.2 ranger_0.13.1 broom_0.8.0 evaluate_0.15 fastmap_1.1.0 ## [67] yaml_2.3.5 ModelMetrics_1.2.2.2 knitr_1.39 fs_1.5.2 zip_2.2.0 forestplot_2.0.1 ## [73] coin_1.4-2 future_1.26.1 nlme_3.1-157 xml2_1.3.3 compiler_4.2.0 rstudioapi_0.13 ## [79] png_0.1-7 e1071_1.7-9 reprex_2.0.1 bslib_0.3.1 stringi_1.7.6 highr_0.9 ## [85] gdtools_0.2.4 Matrix_1.4-1 vctrs_0.4.1 pillar_1.7.0 lifecycle_1.0.1 jquerylib_0.1.4 ## [91] bitops_1.0-7 data.table_1.14.2 R6_2.5.1 latticeExtra_0.6-29 bookdown_0.27 gridExtra_2.3 ## [97] parallelly_1.31.1 codetools_0.2-18 MASS_7.3-57 assertthat_0.2.1 rprojroot_2.0.3 withr_2.5.0 ## [103] multcomp_1.4-19 parallel_4.2.0 hms_1.1.1 rpart_4.1.16 timeDate_3043.102 class_7.3-20 ## [109] rmarkdown_2.14 inum_1.0-4 pROC_1.18.0 lubridate_1.8.0 base64enc_0.1-3 "],["references-1.html", "Part 4 References", " Part 4 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
